# 第十三章：多模型协商

本章介绍 ZeroClaw 的多模型协商功能，让多个 AI 共同完成任务。

---

## 目录

1. [功能概述](#功能概述)
2. [协商策略](#协商策略)
3. [启用协商](#启用协商)
4. [使用示例](#使用示例)
5. [最佳实践](#最佳实践)

---

## 功能概述

### 什么是多模型协商？

想象你遇到了一个难题：
- 方式一：问一个专家，听他的答案
- 方式二：问多个专家，综合他们的意见

**多模型协商**就是后者 —— ZeroClaw 会同时让多个 AI 模型回答你的问题，然后智能地综合出最佳答案。

### 为什么需要协商？

| 单一模型 | 多模型协商 |
|----------|------------|
| 可能出错 | 多个模型互相验证 |
| 单一视角 | 多角度分析 |
| 不确定性高 | 置信度更高 |
| 依赖单一判断 | 更可靠 |

### 适用场景

| 场景 | 是否推荐协商 |
|------|--------------|
| 简单问答 | ❌ 不需要 |
| 重要决策 | ✅ 推荐 |
| 复杂推理 | ✅ 推荐 |
| 编程问题 | ⚠️ 复杂问题推荐 |
| 创意写作 | ✅ 推荐 |
| 数学问题 | ✅ 推荐 |

---

## 协商策略

ZeroClaw 提供多种协商策略：

### 1. 投票模式 (Voting)

**原理**：多个模型投票，多数胜出

**适合**：事实性问题、选择题

**示例**：

```
问题：地球到月球的平均距离是多少？

模型 A 回答：38万公里
模型 B 回答：384,400公里  
模型 C 回答：约38万公里

协商结果：约38万公里（3票中有2票相近）
置信度：67%
```

### 2. 最佳答案模式 (BestOfN)

**原理**：选择质量最高的单一回答

**适合**：创意写作、开放性问题

**示例**：

```
问题：写一首关于春天的诗

模型 A 写的诗：[评分为 7/10]
模型 B 写的诗：[评分为 9/10]
模型 C 写的诗：[评分为 6/10]

协商结果：使用模型 B 的作品
```

### 3. 级联优化模式 (Cascade)

**原理**：第一个模型回答，后续模型优化改进

**适合**：复杂推理、学术论文、代码审查

**示例**：

```
问题：设计一个电商系统架构

模型 A：给出初步设计
  ↓
模型 B：发现潜在问题，提出改进
  ↓  
模型 C：进一步优化细节

最终输出：经过三轮优化的完整设计
```

### 4. 共识模式 (Consensus)

**原理**：所有模型必须达成一致

**适合**：关键决策、需要高度确定性

**示例**：

```
问题：这段代码是否有 bug？

模型 A：没有发现 bug
模型 B：没有发现 bug
模型 C：发现一个潜在问题

协商结果：共识失败，需要人工审查
```

### 5. 自洽性模式 (SelfConsistency)

**原理**：选择最一致的答案

**适合**：数学问题、逻辑推理

**示例**：

```
问题：计算 2^10

模型 A：1024
模型 B：1024
模型 C：1024

协商结果：1024（完全一致）
置信度：100%
```

---

## 启用协商

### 方式一：命令行

```bash
# 使用投票模式
zeroclaw agent --negotiate voting

# 使用最佳答案模式
zeroclaw agent --negotiate best

# 使用级联优化模式
zeroclaw agent --negotiate cascade
```

### 方式二：配置文件

编辑 `~/.zeroclaw/config.yaml`：

```yaml
negotiation:
  # 启用协商
  enabled: true
  
  # 默认策略
  strategy: voting  # voting/best/cascade/consensus/self-consistency
  
  # 参与协商的模型
  models:
    - provider: openai
      model: gpt-4o
    - provider: anthropic
      model: claude-sonnet
    - provider: deepseek
      model: deepseek-chat
  
  # 置信度阈值
  confidence_threshold: 0.7
```

### 方式三：守护进程模式

```bash
zeroclaw daemon --negotiate voting
```

---

## 使用示例

### 示例 1：重要决策

```
用户: 我应该选择哪个云服务商？AWS、GCP 还是 Azure？

ZeroClaw [投票模式]:
正在咨询多个模型...

模型分析：

GPT-4o 建议：AWS
理由：生态最完善，市场占有率最高，文档丰富...

Claude Sonnet 建议：GCP  
理由：价格竞争力强，机器学习工具优秀，Kubernetes 原生支持...

DeepSeek 建议：AWS
理由：国内用户访问友好，CDN 节点多...

协商结果：
推荐：AWS（2/3 模型推荐）

综合理由：
- 市场成熟度最高
- 文档和社区支持最完善
- 服务种类最全面

建议你根据具体需求：
- 需要机器学习 → 考虑 GCP
- 需要企业支持 → AWS
- 需要成本优化 → 比较具体服务定价
```

### 示例 2：代码审查

```
用户: 帮我审查这段代码是否有问题

[代码...]

ZeroClaw [级联优化模式]:
正在进行多轮审查...

第一轮 (GPT-4o)：
✓ 代码逻辑正确
⚠ 缺少错误处理
⚠ 变量命名可以改进

第二轮 (Claude Sonnet)：
✓ 同意以上分析
⚠ 补充：存在潜在的并发问题
建议添加锁机制

第三轮 (DeepSeek)：
✓ 确认问题
建议的改进方案：
1. 添加 try-catch 错误处理
2. 使用更清晰的命名
3. 添加线程同步

最终审查报告：
[综合三轮分析的完整报告]
```

### 示例 3：创意写作

```
用户: 帮我写一段关于人工智能未来的展望

ZeroClaw [最佳答案模式]:
正在让多个模型创作...

模型 A 的作品：[展示]
模型 B 的作品：[展示]  ← 最佳
模型 C 的作品：[展示]

选择理由：
模型 B 的作品在创意性、逻辑性和可读性方面表现最佳。
- 独特的视角
- 丰富的比喻
- 清晰的结构

最终输出：[模型 B 的作品]
```

---

## 最佳实践

### 何时使用协商

**推荐使用**：
- 重要决策需要多方验证
- 复杂问题需要多角度分析
- 需要高置信度的答案
- 创意任务需要选择最佳方案

**不推荐使用**：
- 简单的日常对话
- 时间敏感的请求
- 成本敏感的场景

### 选择合适的策略

| 任务类型 | 推荐策略 | 原因 |
|----------|----------|------|
| 事实性问题 | voting | 多数胜出更可靠 |
| 创意写作 | best | 选择最佳创意 |
| 代码审查 | cascade | 逐步优化 |
| 关键决策 | consensus | 需要一致意见 |
| 数学问题 | self-consistency | 寻找一致答案 |

### 成本考虑

协商会增加 API 调用次数：

| 策略 | 调用次数 | 成本 |
|------|----------|------|
| voting | 3x | 中等 |
| best | 3x | 中等 |
| cascade | 3x+ | 较高 |
| consensus | 3x+ | 较高 |

**建议**：
- 为协商设置预算限制
- 只在重要任务启用协商
- 使用便宜的模型参与协商

---

## 配置高级选项

### 模型权重

```yaml
negotiation:
  models:
    - provider: openai
      model: gpt-4o
      weight: 1.5  # 更高的权重
      
    - provider: anthropic
      model: claude-sonnet
      weight: 1.0
      
    - provider: deepseek
      model: deepseek-chat
      weight: 0.8  # 较低的权重
```

### 失败处理

```yaml
negotiation:
  # 如果协商失败怎么办
  on_failure: fallback  # fallback/halt/retry
  
  # 回退到单一模型
  fallback_model:
    provider: openai
    model: gpt-4o
```

### 超时设置

```yaml
negotiation:
  # 每个模型的超时时间
  timeout_seconds: 30
  
  # 总协商超时
  total_timeout_seconds: 120
```

---

## 常见问题

### Q: 协商会让回答变慢吗？

**会**，因为需要多个模型同时处理。但响应时间通常是单模型的 1.5 倍左右（并行调用）。

### Q: 协商会增加成本吗？

**会**，因为调用了多个模型。但你可以在配置中使用便宜的模型参与协商。

### Q: 如何知道协商是否成功？

ZeroClaw 会在回答中显示：

```
[协商结果 | 策略: voting | 置信度: 85%]
```

### Q: 可以只对某些问题启用协商吗？

可以，使用关键词触发：

```yaml
negotiation:
  enabled: false  # 默认关闭
  
  # 触发协商的关键词
  trigger_keywords:
    - "重要"
    - "请确认"
    - "多个模型"
```

---

## 下一步

1. **设置定时任务** → [自动化与定时任务](./14-automation.md)
2. **部署到服务器** → [远程部署](./15-deployment.md)
3. **了解安全设置** → [安全设置](./17-security.md)

---

[← 上一章：记忆系统](./12-memory.md) | [返回目录](./README.md) | [下一章：自动化与定时任务 →](./14-automation.md)
